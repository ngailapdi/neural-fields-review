[{"Abstract":"It is widely accepted that reasoning about object shape is important for object recognition. However, the most powerful object recognition methods today do not explicitly make\nuse of object shape during learning. In this work, motivated by recent developments in low-shot learning, findings in developmental psychology, and the increased use of synthetic data in computer vision research, we investigate how reasoning about 3D shape can be used to improve low-shot learning methods\u2019 generalization performance. We propose a new way to improve existing low-shot learning approaches by learning a discriminative embedding space using 3D object shape, and using this embedding by learning how to map images into it. Our new approach improves the performance of image-only low-shot learning approaches\non multiple datasets. We also introduce Toys4K, a 3D object dataset with the largest number of object categories currently available, which supports low-shot learning.","Authors (format: First Last)":"Stefan Stojanov, Anh Thai, James M. Rehg","BibTex":"@article{stojanov21cvpr,       title={Using Shape to Categorize: Low-Shot Learning with an Explicit Shape Bias},       author={Stefan Stojanov and Anh Thai and James M. Rehg},       booktitle = {CVPR},       year      = {2021} }","Code Release (Github link, or enter \"Coming soon\")":"https://github.com/rehg-lab/lowshot-shapebias","Data Release (link)":"","Date Published (MM/DD/YYYY)":"03/30/2021","Email Address":"sstojanov@gatech.edu","Keywords":"Low-shot Learning","PDF link (arXiv preferred) ":"https://arxiv.org/pdf/2101.07296.pdf","Project webpage link":"https://rehg-lab.github.io/publication-pages/lowshot-shapebias/","Supplement PDF (link)":"","Talk/Video (link, Youtube preferred)":"","Timestamp":"12/12/2022 16:10:05","Title":"Using Shape to Categorize: Low-Shot Learning with an Explicit Shape Bias","UID":"","Venue":"CVPR 2021"},{"Abstract":"Deep neural networks (DNNs) have achieved unprecedented performance on a wide range of complex tasks, rapidly outpacing our understanding of the nature of their solutions. This has caused a recent surge of interest in methods for rendering modern neural systems more interpretable. In this work, we propose to address the interpretability problem in modern DNNs using the rich history of problem descriptions, theories and experimental methods developed by cognitive psychologists to study the human mind. To explore the potential value of these tools, we chose a well-established analysis from developmental psychology that explains how children learn word labels for objects, and applied that analysis to DNNs. Using datasets of stimuli inspired by the original cognitive psychology experiments, we find that state-of-the-art one shot learning models trained on ImageNet exhibit a similar bias to that observed in humans: they prefer to categorize objects according to shape rather than color. The magnitude of this shape bias varies greatly among architecturally identical, but differently seeded models, and even fluctuates within seeds throughout training, despite nearly equivalent classification performance. These results demonstrate the capability of tools from cognitive psychology for exposing hidden computational properties of DNNs, while concurrently providing us with a computational model for human word learning.","Authors (format: First Last)":"Samuel Ritter, David G.T. Barrett, Adam Santoro, Matt M. Botvinick","BibTex":"@inproceedings{ritter2017cognitive,   title={Cognitive psychology for deep neural networks: A shape bias case study},   author={Ritter, Samuel and Barrett, David GT and Santoro, Adam and Botvinick, Matt M},   booktitle={International conference on machine learning},   pages={2940--2949},   year={2017},   organization={PMLR} }","Code Release (Github link, or enter \"Coming soon\")":"","Data Release (link)":"","Date Published (MM/DD/YYYY)":"08/06/2017","Email Address":"sstojanov@gatech.edu","Keywords":"shape-bias, computer-vision, neural-networks","PDF link (arXiv preferred) ":"https://arxiv.org/pdf/1706.08606.pdf","Project webpage link":"","Supplement PDF (link)":"","Talk/Video (link, Youtube preferred)":"","Timestamp":"12/13/2022 12:36:56","Title":"Cognitive Psychology for Deep Neural Networks: A Shape Bias Case Study","UID":"","Venue":"ICML"},{"Abstract":"We ask if certain dimensions of perceptual similarity are weighted more heavily than others in determining word extension. The specific dimensions examined were shape, size, and texture. In four experiments, subjects were asked either to extend a novel count noun to new instances or, in a nonword classification task, to put together objects that go together. The subjects were 2-year-olds, 3-year-olds, and adults. The results of all four experiments indicate that 2- and 3-year-olds and adults all weight shape more heavily than they do size or texture. This observed emphasis on shape, however, depends on the age of the subject and the task. First, there is a developmental trend. The shape bias increases in strength and generality from 2 to 3 years of age and more markedly from early childhood to adulthood. Second, in young children, the shape bias is much stronger in word extension than in nonword classification tasks. These results suggest that the development of the shape bias originates in language learning\u2014it reflects a fact about language\u2014and does not stem from general perceptual processes.","Authors (format: First Last)":"Barbara Landau, Linda B.Smith, Susan S.Jones","BibTex":"@article{LANDAU1988299, title = {The importance of shape in early lexical learning}, journal = {Cognitive Development}, volume = {3}, number = {3}, pages = {299-321}, year = {1988}, issn = {0885-2014}, doi = {https://doi.org/10.1016/0885-2014(88)90014-7}, url = {https://www.sciencedirect.com/science/article/pii/0885201488900147}, author = {Barbara Landau and Linda B. Smith and Susan S. Jones}, abstract = {We ask if certain dimensions of perceptual similarity are weighted more heavily than others in determining word extension. The specific dimensions examined were shape, size, and texture. In four experiments, subjects were asked either to extend a novel count noun to new instances or, in a nonword classification task, to put together objects that go together. The subjects were 2-year-olds, 3-year-olds, and adults. The results of all four experiments indicate that 2- and 3-year-olds and adults all weight shape more heavily than they do size or texture. This observed emphasis on shape, however, depends on the age of the subject and the task. First, there is a developmental trend. The shape bias increases in strength and generality from 2 to 3 years of age and more markedly from early childhood to adulthood. Second, in young children, the shape bias is much stronger in word extension than in nonword classification tasks. These results suggest that the development of the shape bias originates in language learning\u2014it reflects a fact about language\u2014and does not stem from general perceptual processes.} }","Code Release (Github link, or enter \"Coming soon\")":"","Data Release (link)":"","Date Published (MM/DD/YYYY)":"07/01/1988","Email Address":"sstojanov@gatech.edu","Keywords":"shape-bias, dev-psych","PDF link (arXiv preferred) ":"https://www.sciencedirect.com/science/article/pii/0885201488900147?via%3Dihub","Project webpage link":"","Supplement PDF (link)":"","Talk/Video (link, Youtube preferred)":"","Timestamp":"12/13/2022 12:39:42","Title":"The importance of shape in early lexical learning","UID":"","Venue":"Cognitive Development"},{"Abstract":"A hallmark of the deep learning era for computer vision is the successful use of\nlarge-scale labeled datasets to train feature representations for tasks ranging from\nobject recognition and semantic segmentation to optical flow estimation and novel\nview synthesis of 3D scenes. In this work, we aim to learn dense discriminative\nobject representations for low-shot category recognition without requiring any\ncategory labels. To this end, we propose Deep Object Patch Encodings (DOPE),\nwhich can be trained from multiple views of object instances without any category\nor semantic object part labels. To train DOPE, we assume access to sparse depths,\nforeground masks and known cameras, to obtain pixel-level correspondences\nbetween views of an object, and use this to formulate a self-supervised learning\ntask to learn discriminative object patches. We find that DOPE can directly be used\nfor low-shot classification of novel categories using local-part matching, and is\ncompetitive with and outperforms supervised and self-supervised learning baselines.","Authors (format: First Last)":"Stefan Stojanov, Anh Thai, Zixuan Huang, James M. Rehg","BibTex":"@inproceedings{stojanov2022learning,   title={Learning Dense Object Descriptors from Multiple Views for Low-shot Category Generalization},   author={Stojanov, Stefan and Thai, Ngoc Anh and Huang, Zixuan and Rehg, James Matthew},   booktitle={Advances in Neural Information Processing Systems} }","Code Release (Github link, or enter \"Coming soon\")":"https://github.com/rehg-lab/dope_selfsup","Data Release (link)":"","Date Published (MM/DD/YYYY)":"11/28/2022","Email Address":"athai6@gatech.edu","Keywords":"self-supervised learning, low-shot learning","PDF link (arXiv preferred) ":"https://arxiv.org/pdf/2211.15059.pdf","Project webpage link":"https://sstojanov.github.io/projects/dope_selfsup.html","Supplement PDF (link)":"","Talk/Video (link, Youtube preferred)":"https://www.youtube.com/watch?v=qaArkLiiymkv","Timestamp":"12/13/2022 13:22:54","Title":"Learning Dense Object Descriptors from Multiple Views for Low-shot Category Generalization","UID":"","Venue":"NeurIPS 2022"},{"Abstract":"Recent work has shown that large text-based neural language models, trained with conventional supervised learning objectives, acquire a surprising propensity for few- and one-shot learning. Here, we show that an embodied agent situated in a simulated 3D world, and endowed with a novel dual-coding external memory, can exhibit similar one-shot word learning when trained with conventional reinforcement learning algorithms. After a single introduction to a novel object via continuous visual perception and a language prompt (\"This is a dax\"), the agent can re-identify the object and manipulate it as instructed (\"Put the dax on the bed\"). In doing so, it seamlessly integrates short-term, within-episode knowledge of the appropriate referent for the word \"dax\" with long-term lexical and motor knowledge acquired across episodes (i.e. \"bed\" and \"putting\"). We find that, under certain training conditions and with a particular memory writing mechanism, the agent's one-shot word-object binding generalizes to novel exemplars within the same ShapeNet category, and is effective in settings with unfamiliar numbers of objects. We further show how dual-coding memory can be exploited as a signal for intrinsic motivation, stimulating the agent to seek names for objects that may be useful for later executing instructions. Together, the results demonstrate that deep neural networks can exploit meta-learning, episodic memory and an explicitly multi-modal environment to account for 'fast-mapping', a fundamental pillar of human cognitive development and a potentially transformative capacity for agents that interact with human users. ","Authors (format: First Last)":"Felix Hill, Olivier Tieleman, Tamara von Glehn, Nathaniel Wong, Hamza Merzic, Stephen Clark","BibTex":"@inproceedings{ hill2021grounded, title={Grounded Language Learning Fast and Slow}, author={Felix Hill and Olivier Tieleman and Tamara von Glehn and Nathaniel Wong and Hamza Merzic and Stephen Clark}, booktitle={International Conference on Learning Representations}, year={2021}, url={https://openreview.net/forum?id=wpSWuz_hyqA} }","Code Release (Github link, or enter \"Coming soon\")":"https://github.com/deepmind/dm_fast_mapping","Data Release (link)":"","Date Published (MM/DD/YYYY)":"09/03/2020","Email Address":"athai6@gatech.edu","Keywords":"Perception, Language, Fast Mapping","PDF link (arXiv preferred) ":"https://arxiv.org/pdf/2009.01719.pdf","Project webpage link":"","Supplement PDF (link)":"","Talk/Video (link, Youtube preferred)":"","Timestamp":"12/20/2022 13:34:31","Title":"Grounded Language Learning Fast and Slow","UID":"","Venue":"ICLR 2021"}]
